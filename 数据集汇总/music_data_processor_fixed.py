# file: music_data_processor_complete.py
import pandas as pd
import numpy as np
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import json
from difflib import SequenceMatcher

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class UnifiedMusicDataProcessor:
    """ç»Ÿä¸€éŸ³ä¹æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, data_path="."):
        self.data_path = data_path
        self.data = {}
        self.song_id_mapping = {}
        self.user_id_mapping = {}
        
    def load_all_data_systematic(self):
        """ç³»ç»ŸåŒ–åŠ è½½æ‰€æœ‰æ•°æ®"""
        print("="*80)
        print("ç³»ç»ŸåŒ–åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶...")
        print("="*80)
        
        data_files = {
            'songs': ('all_songs.csv', 'æ­Œæ›²åŸºæœ¬ä¿¡æ¯'),
            'users': ('ç”¨æˆ·æ•°æ®_20260124_200012.csv', 'ç”¨æˆ·åŸºæœ¬ä¿¡æ¯'),
            'collected': ('collected_user_ids_20260119_173402.csv', 'ç”¨æˆ·-æ­Œæ›²å…³è”'),
            'likes': ('user_like_songs_20260120_132245.csv', 'ç”¨æˆ·å–œæ¬¢æ­Œæ›²'),
            'plays': ('user_play_history_20260120_132245.csv', 'ç”¨æˆ·æ’­æ”¾å†å²'),
            'playlist_info': ('playlist_info_20260124_144712.csv', 'æ­Œå•ä¿¡æ¯'),
            'playlist_songs': ('playlist_songs_20260124_144712.csv', 'æ­Œå•æ­Œæ›²'),
            'comments': ('song_comments_20260124_001212.csv', 'æ­Œæ›²è¯„è®º'),
            'similarity': ('song_similarity_20260124_001212.csv', 'æ­Œæ›²ç›¸ä¼¼åº¦'),
            'tags': ('song_tags_20260124_001212.csv', 'æ­Œæ›²æ ‡ç­¾'),
            'external_history': ('User Listening History.csv', 'å¤–éƒ¨æ”¶å¬å†å²'),
            'external_music': ('Music Info.csv', 'å¤–éƒ¨éŸ³ä¹ä¿¡æ¯')
        }
        
        self.data = {}
        loaded_counts = {}
        
        for key, (filename, description) in data_files.items():
            try:
                filepath = os.path.join(self.data_path, filename)
                if os.path.exists(filepath):
                    # å¯¹äºå¤§æ•°æ®æ–‡ä»¶è¿›è¡Œé‡‡æ ·
                    if filename == 'User Listening History.csv':
                        print(f"åŠ è½½ {description}...")
                        # è¯»å–å‰100ä¸‡è¡Œï¼Œé¿å…å†…å­˜é—®é¢˜
                        self.data[key] = pd.read_csv(filepath, nrows=1000000)
                    else:
                        self.data[key] = pd.read_csv(filepath)
                    
                    loaded_counts[key] = len(self.data[key])
                    print(f"  âœ“ {description}: {loaded_counts[key]:,} æ¡è®°å½•")
                    
                    # æ˜¾ç¤ºå‰å‡ åˆ—ä¿¡æ¯
                    print(f"    åˆ—: {list(self.data[key].columns[:5])}...")
                else:
                    print(f"  âœ— æ–‡ä»¶æœªæ‰¾åˆ°: {filename}")
            except Exception as e:
                print(f"  âœ— åŠ è½½ {description} å¤±è´¥: {str(e)}")
                self.data[key] = pd.DataFrame()
        
        print("\n" + "="*80)
        print(f"æˆåŠŸåŠ è½½ {len([k for k in loaded_counts if loaded_counts[k] > 0])}/{len(data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
        
        return self.data
    
    def create_unified_song_mapping(self):
        """åˆ›å»ºç»Ÿä¸€çš„æ­Œæ›²IDæ˜ å°„"""
        print("\n" + "="*80)
        print("åˆ›å»ºç»Ÿä¸€çš„æ­Œæ›²IDæ˜ å°„...")
        
        song_mapping = {}
        song_info = {}
        
        # 1. ä»çˆ¬å–æ•°æ®ä¸­è·å–æ­Œæ›²ä¿¡æ¯
        if 'songs' in self.data and not self.data['songs'].empty:
            songs_df = self.data['songs']
            for _, row in songs_df.iterrows():
                song_id = str(row['song_id'])
                song_name = str(row['song_name']).strip().lower()
                artists = str(row['artists']).strip().lower()
                
                key = f"{song_name}||{artists}"
                if key not in song_mapping:
                    song_mapping[key] = {
                        'unified_id': f"song_{len(song_mapping)+1:08d}",
                        'sources': []
                    }
                
                song_mapping[key]['sources'].append({
                    'source': 'internal',
                    'song_id': song_id,
                    'original_song_name': row['song_name'],
                    'original_artists': row['artists']
                })
                
                # ä¿å­˜æ­Œæ›²ä¿¡æ¯
                unified_id = song_mapping[key]['unified_id']
                song_info[unified_id] = {
                    'song_name': row['song_name'],
                    'artists': row['artists'],
                    'album': row.get('album', ''),
                    'duration': row.get('duration', 0),
                    'genre': row.get('genre', ''),
                    'popularity': row.get('popularity', 0),
                    'language': row.get('language', ''),
                    'publish_date': row.get('publish_date', '')
                }
        
        # 2. ä»å¤–éƒ¨æ•°æ®ä¸­è·å–æ­Œæ›²ä¿¡æ¯
        if 'external_music' in self.data and not self.data['external_music'].empty:
            external_df = self.data['external_music']
            for _, row in external_df.iterrows():
                track_id = str(row['track_id'])
                song_name = str(row.get('name', '')).strip().lower()
                artists = str(row.get('artist', '')).strip().lower()
                
                if song_name and artists:
                    key = f"{song_name}||{artists}"
                    
                    if key not in song_mapping:
                        song_mapping[key] = {
                            'unified_id': f"song_{len(song_mapping)+1:08d}",
                            'sources': []
                        }
                    
                    song_mapping[key]['sources'].append({
                        'source': 'external',
                        'song_id': track_id,
                        'original_song_name': row.get('name', ''),
                        'original_artists': row.get('artist', '')
                    })
                    
                    # ä¿å­˜å¤–éƒ¨æ­Œæ›²ä¿¡æ¯
                    unified_id = song_mapping[key]['unified_id']
                    if unified_id not in song_info:
                        song_info[unified_id] = {
                            'song_name': row.get('name', ''),
                            'artists': row.get('artist', ''),
                            'album': '',
                            'duration': row.get('duration_ms', 0),
                            'genre': row.get('genre', ''),
                            'popularity': 0,
                            'language': '',
                            'publish_date': str(row.get('year', '')) if pd.notna(row.get('year')) else ''
                        }
        
        # 3. åˆ›å»ºåŒå‘æ˜ å°„
        self.song_id_mapping = {
            'key_to_unified': {},
            'unified_to_sources': {}
        }
        
        for key, mapping_info in song_mapping.items():
            unified_id = mapping_info['unified_id']
            self.song_id_mapping['key_to_unified'][key] = unified_id
            
            for source_info in mapping_info['sources']:
                source_key = f"{source_info['source']}_{source_info['song_id']}"
                self.song_id_mapping['key_to_unified'][source_key] = unified_id
            
            self.song_id_mapping['unified_to_sources'][unified_id] = mapping_info['sources']
        
        self.song_info = song_info
        
        print(f"åˆ›å»ºäº† {len(song_mapping)} ä¸ªç»Ÿä¸€æ­Œæ›²ID")
        print(f"æ˜ å°„äº† {len(self.song_id_mapping['key_to_unified'])} ä¸ªåŸå§‹ID")
        
        return self.song_id_mapping
    
    def create_unified_user_mapping(self):
        """åˆ›å»ºç»Ÿä¸€çš„ç”¨æˆ·IDæ˜ å°„"""
        print("\n" + "="*80)
        print("åˆ›å»ºç»Ÿä¸€çš„ç”¨æˆ·IDæ˜ å°„...")
        
        user_mapping = {}
        user_info = {}
        
        # 1. ä»ç”¨æˆ·æ•°æ®ä¸­è·å–ç”¨æˆ·ä¿¡æ¯
        if 'users' in self.data and not self.data['users'].empty:
            users_df = self.data['users']
            for _, row in users_df.iterrows():
                user_id = str(row['user_id'])
                nickname = str(row.get('nickname', '')).strip().lower()
                
                unified_id = f"user_{len(user_mapping)+1:08d}"
                user_mapping[user_id] = unified_id
                
                # ä¿å­˜ç”¨æˆ·ä¿¡æ¯
                user_info[unified_id] = {
                    'original_id': user_id,
                    'nickname': row.get('nickname', ''),
                    'gender': row.get('gender', 0),
                    'age': row.get('age', 0),
                    'province': row.get('province', ''),
                    'city': row.get('city', ''),
                    'listen_songs': row.get('listen_songs', 0),
                    'create_time': row.get('create_time', ''),
                    'source': 'internal'
                }
        
        # 2. ä»å¤–éƒ¨æ•°æ®ä¸­è·å–ç”¨æˆ·ä¿¡æ¯
        if 'external_history' in self.data and not self.data['external_history'].empty:
            external_df = self.data['external_history']
            external_users = external_df['user_id'].unique()[:100000]  # é™åˆ¶æ•°é‡
            
            for user_id in external_users:
                user_id_str = f"ext_{user_id}"
                
                if user_id_str not in user_mapping:
                    unified_id = f"user_{len(user_mapping)+1:08d}"
                    user_mapping[user_id_str] = unified_id
                    
                    user_info[unified_id] = {
                        'original_id': user_id_str,
                        'nickname': f'å¤–éƒ¨ç”¨æˆ·_{user_id}',
                        'gender': 0,
                        'age': 25,
                        'province': '',
                        'city': '',
                        'listen_songs': 0,
                        'create_time': '',
                        'source': 'external'
                    }
        
        self.user_id_mapping = user_mapping
        self.user_info = user_info
        
        print(f"åˆ›å»ºäº† {len(user_mapping)} ä¸ªç»Ÿä¸€ç”¨æˆ·ID")
        
        return self.user_id_mapping
    
    def build_interaction_matrix_with_mapping(self):
        """ä½¿ç”¨ç»Ÿä¸€IDæ˜ å°„æ„å»ºäº¤äº’çŸ©é˜µ"""
        print("\n" + "="*80)
        print("æ„å»ºç»Ÿä¸€çš„äº¤äº’çŸ©é˜µ...")
        
        all_interactions = []
        
        # 1. å¤„ç†æ’­æ”¾å†å²æ•°æ®
        if 'plays' in self.data and not self.data['plays'].empty:
            print("1. å¤„ç†æ’­æ”¾å†å²æ•°æ®...")
            plays_df = self.data['plays'].copy()
            
            # ç»Ÿä¸€åˆ—å
            plays_df['user_id'] = plays_df['user_id'].astype(str)
            plays_df['song_id'] = plays_df['song_id'].astype(str)
            
            # åº”ç”¨æ˜ å°„
            plays_df['unified_user_id'] = plays_df['user_id'].map(self.user_id_mapping)
            plays_df['unified_song_id'] = plays_df.apply(
                lambda x: self._get_unified_song_id(x['song_id'], x.get('song_name', ''), x.get('artists', '')),
                axis=1
            )
            
            # è¿‡æ»¤æ— æ•ˆæ˜ å°„
            plays_df = plays_df[plays_df['unified_user_id'].notna() & plays_df['unified_song_id'].notna()]
            
            # è®¡ç®—æƒé‡
            plays_df['play_count'] = plays_df['play_count'].fillna(0).astype(float)
            plays_df['score'] = plays_df['score'].fillna(0).astype(float)
            
            # ç»„åˆæƒé‡
            plays_df['weight'] = (
                0.7 * np.log1p(plays_df['play_count']) + 
                0.3 * plays_df['score'].clip(0, 10) / 10
            )
            
            plays_df['interaction_type'] = 'play'
            
            all_interactions.append(plays_df[['unified_user_id', 'unified_song_id', 'weight', 'interaction_type']])
            print(f"   æ’­æ”¾å†å²: {len(plays_df):,} æ¡è®°å½•")
        
        # 2. å¤„ç†å–œæ¬¢æ­Œæ›²æ•°æ®
        if 'likes' in self.data and not self.data['likes'].empty:
            print("2. å¤„ç†å–œæ¬¢æ­Œæ›²æ•°æ®...")
            likes_df = self.data['likes'].copy()
            
            likes_df['user_id'] = likes_df['user_id'].astype(str)
            likes_df['song_id'] = likes_df['song_id'].astype(str)
            
            likes_df['unified_user_id'] = likes_df['user_id'].map(self.user_id_mapping)
            likes_df['unified_song_id'] = likes_df.apply(
                lambda x: self._get_unified_song_id(x['song_id'], x.get('song_name', ''), x.get('artists', '')),
                axis=1
            )
            
            likes_df = likes_df[likes_df['unified_user_id'].notna() & likes_df['unified_song_id'].notna()]
            
            # å–œæ¬¢è¡Œä¸ºæƒé‡è¾ƒé«˜
            likes_df['weight'] = 8.0
            likes_df['interaction_type'] = 'like'
            
            all_interactions.append(likes_df[['unified_user_id', 'unified_song_id', 'weight', 'interaction_type']])
            print(f"   å–œæ¬¢æ­Œæ›²: {len(likes_df):,} æ¡è®°å½•")
        
        # 3. å¤„ç†æ”¶è—å…³è”æ•°æ®
        if 'collected' in self.data and not self.data['collected'].empty:
            print("3. å¤„ç†æ”¶è—å…³è”æ•°æ®...")
            collected_df = self.data['collected'].copy()
            
            collected_df['user_id'] = collected_df['user_id'].astype(str)
            collected_df['song_id'] = collected_df['song_id'].astype(str)
            
            collected_df['unified_user_id'] = collected_df['user_id'].map(self.user_id_mapping)
            collected_df['unified_song_id'] = collected_df.apply(
                lambda x: self._get_unified_song_id(x['song_id'], '', ''),
                axis=1
            )
            
            collected_df = collected_df[collected_df['unified_user_id'].notna() & collected_df['unified_song_id'].notna()]
            
            collected_df['weight'] = 5.0
            collected_df['interaction_type'] = 'collect'
            
            all_interactions.append(collected_df[['unified_user_id', 'unified_song_id', 'weight', 'interaction_type']])
            print(f"   æ”¶è—å…³è”: {len(collected_df):,} æ¡è®°å½•")
        
        # 4. å¤„ç†å¤–éƒ¨æ”¶å¬å†å²æ•°æ®
        if 'external_history' in self.data and not self.data['external_history'].empty:
            print("4. å¤„ç†å¤–éƒ¨æ”¶å¬å†å²æ•°æ®...")
            external_df = self.data['external_history'].copy()
            
            # é‡‡æ ·ï¼Œé¿å…æ•°æ®é‡è¿‡å¤§
            if len(external_df) > 500000:
                external_df = external_df.sample(n=500000, random_state=42)
            
            external_df['user_id'] = 'ext_' + external_df['user_id'].astype(str)
            external_df['song_id'] = external_df['track_id'].astype(str)
            
            external_df['unified_user_id'] = external_df['user_id'].map(self.user_id_mapping)
            
            # å¯¹äºå¤–éƒ¨æ•°æ®ï¼Œéœ€è¦é€šè¿‡å¤–éƒ¨éŸ³ä¹ä¿¡æ¯æ¥è·å–ç»Ÿä¸€çš„æ­Œæ›²ID
            if 'external_music' in self.data and not self.data['external_music'].empty:
                external_music = self.data['external_music']
                track_to_info = {}
                for _, row in external_music.iterrows():
                    track_id = str(row['track_id'])
                    track_to_info[track_id] = {
                        'name': str(row.get('name', '')),
                        'artist': str(row.get('artist', ''))
                    }
                
                def get_external_song_id(track_id):
                    if track_id in track_to_info:
                        info = track_to_info[track_id]
                        return self._get_unified_song_id(track_id, info['name'], info['artist'])
                    return None
                
                external_df['unified_song_id'] = external_df['song_id'].apply(get_external_song_id)
            else:
                external_df['unified_song_id'] = None
            
            external_df = external_df[external_df['unified_user_id'].notna() & external_df['unified_song_id'].notna()]
            
            # è®¡ç®—å¤–éƒ¨æ’­æ”¾æƒé‡
            external_df['playcount'] = external_df['playcount'].fillna(0).astype(float)
            external_df['weight'] = np.log1p(external_df['playcount'])
            
            # å½’ä¸€åŒ–æƒé‡åˆ°1-10èŒƒå›´
            max_weight = external_df['weight'].max()
            min_weight = external_df['weight'].min()
            if max_weight > min_weight:
                external_df['weight'] = 1 + 9 * (external_df['weight'] - min_weight) / (max_weight - min_weight)
            
            external_df['interaction_type'] = 'external_play'
            
            all_interactions.append(external_df[['unified_user_id', 'unified_song_id', 'weight', 'interaction_type']])
            print(f"   å¤–éƒ¨æ”¶å¬: {len(external_df):,} æ¡è®°å½•")
        
        # 5. åˆå¹¶æ‰€æœ‰äº¤äº’æ•°æ®
        print("5. åˆå¹¶æ‰€æœ‰äº¤äº’æ•°æ®...")
        if all_interactions:
            combined_interactions = pd.concat(all_interactions, ignore_index=True)
            
            # èšåˆé‡å¤çš„äº¤äº’
            interaction_matrix = combined_interactions.groupby(['unified_user_id', 'unified_song_id']).agg({
                'weight': 'sum',
                'interaction_type': lambda x: ','.join(sorted(set(x)))
            }).reset_index()
            
            interaction_matrix.columns = ['user_id', 'song_id', 'total_weight', 'interaction_types']
            
            print(f"\näº¤äº’çŸ©é˜µç»Ÿè®¡:")
            print(f"  æ€»äº¤äº’æ•°: {len(interaction_matrix):,}")
            print(f"  å”¯ä¸€ç”¨æˆ·æ•°: {interaction_matrix['user_id'].nunique():,}")
            print(f"  å”¯ä¸€æ­Œæ›²æ•°: {interaction_matrix['song_id'].nunique():,}")
            
            # è®¡ç®—ç¨€ç–åº¦
            n_users = interaction_matrix['user_id'].nunique()
            n_songs = interaction_matrix['song_id'].nunique()
            sparsity = 1 - len(interaction_matrix) / (n_users * n_songs)
            print(f"  ç¨€ç–åº¦: {sparsity:.6f}")
            
            return interaction_matrix
        else:
            print("è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•äº¤äº’æ•°æ®!")
            return pd.DataFrame(columns=['user_id', 'song_id', 'total_weight', 'interaction_types'])
    
    def _get_unified_song_id(self, original_id, song_name, artists):
        """è·å–ç»Ÿä¸€çš„æ­Œæ›²ID"""
        # å°è¯•ç›´æ¥é€šè¿‡åŸå§‹IDæŸ¥æ‰¾
        source_key_internal = f"internal_{original_id}"
        source_key_external = f"external_{original_id}"
        
        if source_key_internal in self.song_id_mapping['key_to_unified']:
            return self.song_id_mapping['key_to_unified'][source_key_internal]
        elif source_key_external in self.song_id_mapping['key_to_unified']:
            return self.song_id_mapping['key_to_unified'][source_key_external]
        
        # å°è¯•é€šè¿‡æ­Œæ›²åå’Œè‰ºæœ¯å®¶åæŸ¥æ‰¾
        if song_name and artists:
            song_name_clean = str(song_name).strip().lower()
            artists_clean = str(artists).strip().lower()
            key = f"{song_name_clean}||{artists_clean}"
            
            if key in self.song_id_mapping['key_to_unified']:
                return self.song_id_mapping['key_to_unified'][key]
        
        return None
    
    def create_comprehensive_song_features(self):
        """åˆ›å»ºç»¼åˆçš„æ­Œæ›²ç‰¹å¾"""
        print("\n" + "="*80)
        print("åˆ›å»ºç»¼åˆçš„æ­Œæ›²ç‰¹å¾...")
        
        # ä»song_infoå¼€å§‹æ„å»ºåŸºç¡€ç‰¹å¾
        song_features_data = []
        
        for unified_id, info in self.song_info.items():
            feature_dict = {
                'song_id': unified_id,
                'song_name': info.get('song_name', ''),
                'artists': info.get('artists', ''),
                'album': info.get('album', ''),
                'duration_ms': info.get('duration', 0),
                'genre': info.get('genre', ''),
                'popularity': info.get('popularity', 0),
                'language': info.get('language', ''),
                'publish_year': self._extract_year(info.get('publish_date', ''))
            }
            song_features_data.append(feature_dict)
        
        song_features = pd.DataFrame(song_features_data)
        
        # æ·»åŠ æ ‡ç­¾ç‰¹å¾
        if 'tags' in self.data and not self.data['tags'].empty:
            print("1. æ·»åŠ æ ‡ç­¾ç‰¹å¾...")
            tags_df = self.data['tags'].copy()
            
            # ä¸ºæ ‡ç­¾æ•°æ®åˆ›å»ºç»Ÿä¸€çš„æ­Œæ›²IDæ˜ å°„
            tags_df['unified_song_id'] = tags_df.apply(
                lambda x: self._get_unified_song_id(x['song_id'], x.get('song_name', ''), x.get('artists', '')),
                axis=1
            )
            
            tags_df = tags_df[tags_df['unified_song_id'].notna()]
            
            if not tags_df.empty:
                tag_features = tags_df.groupby('unified_song_id').agg({
                    'score': ['mean', 'count']
                }).reset_index()
                
                tag_features.columns = ['song_id', 'tag_score_mean', 'tag_count']
                song_features = pd.merge(song_features, tag_features, on='song_id', how='left')
        
        # æ·»åŠ è¯„è®ºç‰¹å¾
        if 'comments' in self.data and not self.data['comments'].empty:
            print("2. æ·»åŠ è¯„è®ºç‰¹å¾...")
            comments_df = self.data['comments'].copy()
            
            comments_df['unified_song_id'] = comments_df['song_id'].apply(
                lambda x: self._get_unified_song_id(x, '', '')
            )
            
            comments_df = comments_df[comments_df['unified_song_id'].notna()]
            
            if not comments_df.empty:
                comment_features = comments_df.groupby('unified_song_id').agg({
                    'sentiment_score': ['mean', 'count'],
                    'liked_count': 'sum'
                }).reset_index()
                
                comment_features.columns = ['song_id', 'avg_sentiment', 'comment_count', 'total_likes']
                song_features = pd.merge(song_features, comment_features, on='song_id', how='left')
        
        # æ·»åŠ ç›¸ä¼¼åº¦ç‰¹å¾
        if 'similarity' in self.data and not self.data['similarity'].empty:
            print("3. æ·»åŠ ç›¸ä¼¼åº¦ç‰¹å¾...")
            similarity_df = self.data['similarity'].copy()
            
            similarity_df['unified_song_id'] = similarity_df['song_id'].apply(
                lambda x: self._get_unified_song_id(x, '', '')
            )
            
            similarity_df = similarity_df[similarity_df['unified_song_id'].notna()]
            
            if not similarity_df.empty:
                similarity_features = similarity_df.groupby('unified_song_id').agg({
                    'similarity_score': ['mean', 'max', 'count']
                }).reset_index()
                
                similarity_features.columns = ['song_id', 'avg_similarity', 'max_similarity', 'similar_songs_count']
                song_features = pd.merge(song_features, similarity_features, on='song_id', how='left')
        
        # æ·»åŠ æ­Œå•ç‰¹å¾
        if 'playlist_songs' in self.data and not self.data['playlist_songs'].empty:
            print("4. æ·»åŠ æ­Œå•ç‰¹å¾...")
            playlist_df = self.data['playlist_songs'].copy()
            
            playlist_df['unified_song_id'] = playlist_df.apply(
                lambda x: self._get_unified_song_id(x['song_id'], x.get('song_name', ''), x.get('artists', '')),
                axis=1
            )
            
            playlist_df = playlist_df[playlist_df['unified_song_id'].notna()]
            
            if not playlist_df.empty:
                playlist_features = playlist_df.groupby('unified_song_id').agg({
                    'playlist_id': 'nunique',
                    'order': 'mean'
                }).reset_index()
                
                playlist_features.columns = ['song_id', 'playlist_count', 'avg_playlist_order']
                song_features = pd.merge(song_features, playlist_features, on='song_id', how='left')
        
        # æ·»åŠ å¤–éƒ¨éŸ³é¢‘ç‰¹å¾
        print("5. æ·»åŠ éŸ³é¢‘ç‰¹å¾...")
        audio_features = self._extract_audio_features()
        if audio_features is not None:
            song_features = pd.merge(song_features, audio_features, on='song_id', how='left')
        
        # å¤„ç†ç¼ºå¤±å€¼
        print("6. å¤„ç†ç¼ºå¤±å€¼...")
        song_features = self._handle_missing_values(song_features)
        
        # ç‰¹å¾å·¥ç¨‹
        print("7. ç‰¹å¾å·¥ç¨‹...")
        song_features = self._engineer_features(song_features)
        
        print(f"\nâœ“ æ­Œæ›²ç‰¹å¾åˆ›å»ºå®Œæˆ! æœ€ç»ˆå½¢çŠ¶: {song_features.shape}")
        
        return song_features
    
    def _extract_audio_features(self):
        """æå–éŸ³é¢‘ç‰¹å¾"""
        if 'external_music' not in self.data or self.data['external_music'].empty:
            return None
        
        audio_features_data = []
        external_music = self.data['external_music']
        
        for _, row in external_music.iterrows():
            track_id = str(row['track_id'])
            unified_id = self._get_unified_song_id(track_id, row.get('name', ''), row.get('artist', ''))
            
            if unified_id:
                feature_dict = {
                    'song_id': unified_id,
                    'danceability': row.get('danceability', 0.5),
                    'energy': row.get('energy', 0.5),
                    'key': row.get('key', 0),
                    'loudness': row.get('loudness', -10),
                    'mode': row.get('mode', 1),
                    'speechiness': row.get('speechiness', 0),
                    'acousticness': row.get('acousticness', 0),
                    'instrumentalness': row.get('instrumentalness', 0),
                    'liveness': row.get('liveness', 0),
                    'valence': row.get('valence', 0.5),
                    'tempo': row.get('tempo', 120),
                    'time_signature': row.get('time_signature', 4)
                }
                audio_features_data.append(feature_dict)
        
        if audio_features_data:
            audio_features = pd.DataFrame(audio_features_data)
            # èšåˆé‡å¤é¡¹ï¼ˆå¦‚æœæœ‰ï¼‰
            audio_features = audio_features.groupby('song_id').mean().reset_index()
            return audio_features
        
        return None
    
    def _handle_missing_values(self, df):
        """å¤„ç†ç¼ºå¤±å€¼"""
        # æ•°å€¼ç‰¹å¾ç”¨ä¸­ä½æ•°å¡«å……
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if df[col].isnull().any():
                median_val = df[col].median()
                df[col].fillna(median_val, inplace=True)
        
        # åˆ†ç±»ç‰¹å¾ç”¨ä¼—æ•°å¡«å……
        categorical_cols = ['genre', 'language']
        for col in categorical_cols:
            if col in df.columns and df[col].isnull().any():
                mode_val = df[col].mode()[0] if not df[col].mode().empty else 'æœªçŸ¥'
                df[col].fillna(mode_val, inplace=True)
        
        return df
    
    def _engineer_features(self, df):
        """ç‰¹å¾å·¥ç¨‹"""
        # åˆ›å»ºæ­Œæ›²å¹´é¾„ç‰¹å¾
        if 'publish_year' in df.columns:
            current_year = datetime.now().year
            df['song_age'] = current_year - df['publish_year']
            df['song_age'] = df['song_age'].clip(lower=0)
        
        # åˆ›å»ºæ—¶é•¿ç‰¹å¾ï¼ˆåˆ†é’Ÿï¼‰
        if 'duration_ms' in df.columns:
            df['duration_minutes'] = df['duration_ms'] / 60000
        
        # æµè¡Œåº¦åˆ†ç»„
        if 'popularity' in df.columns:
            try:
                df['popularity_group'] = pd.qcut(
                    df['popularity'], 
                    q=5, 
                    labels=['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜'],
                    duplicates='drop'
                )
            except:
                df['popularity_group'] = pd.cut(
                    df['popularity'],
                    bins=5,
                    labels=['å¾ˆä½', 'ä½', 'ä¸­', 'é«˜', 'å¾ˆé«˜']
                )
        
        # ç»„åˆéŸ³é¢‘ç‰¹å¾
        audio_cols = ['danceability', 'energy', 'valence', 'tempo']
        available_audio = [col for col in audio_cols if col in df.columns]
        
        if len(available_audio) >= 2:
            df['danceability'] = df['danceability'].fillna(0.5)
            df['energy'] = df['energy'].fillna(0.5)
            df['valence'] = df['valence'].fillna(0.5)
            
            df['energy_dance'] = (df['danceability'] + df['energy']) / 2
            df['mood_score'] = (df['valence'] + df['energy']) / 2
        
        return df
    
    def _extract_year(self, date_str):
        """ä»æ—¥æœŸå­—ç¬¦ä¸²ä¸­æå–å¹´ä»½"""
        if pd.isna(date_str):
            return 2020
        
        try:
            # å°è¯•è§£ææ—¥æœŸå­—ç¬¦ä¸²
            if isinstance(date_str, str):
                # ç§»é™¤æ—¶é—´éƒ¨åˆ†
                date_part = date_str.split(' ')[0]
                # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
                for fmt in ['%Y-%m-%d', '%Y/%m/%d', '%Y.%m.%d', '%Y']:
                    try:
                        dt = datetime.strptime(date_part, fmt)
                        return dt.year
                    except:
                        continue
            
            # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥ä½œä¸ºå¹´ä»½
            if isinstance(date_str, (int, float)):
                return int(date_str)
        except:
            pass
        
        return 2020
    
    def create_comprehensive_user_features(self, interaction_matrix):
        """åˆ›å»ºç»¼åˆçš„ç”¨æˆ·ç‰¹å¾"""
        print("\n" + "="*80)
        print("åˆ›å»ºç»¼åˆçš„ç”¨æˆ·ç‰¹å¾...")
        
        user_features_data = []
        
        # ä»ç”¨æˆ·ä¿¡æ¯å¼€å§‹
        for unified_id, info in self.user_info.items():
            feature_dict = {
                'user_id': unified_id,
                'nickname': info.get('nickname', ''),
                'gender': info.get('gender', 0),
                'age': info.get('age', 25),
                'province': info.get('province', ''),
                'city': info.get('city', ''),
                'listen_songs': info.get('listen_songs', 0),
                'source': info.get('source', 'internal')
            }
            user_features_data.append(feature_dict)
        
        user_features = pd.DataFrame(user_features_data)
        
        # ä»äº¤äº’çŸ©é˜µä¸­æå–ç”¨æˆ·è¡Œä¸ºç‰¹å¾
        if not interaction_matrix.empty:
            print("1. ä»äº¤äº’çŸ©é˜µæå–ç”¨æˆ·è¡Œä¸ºç‰¹å¾...")
            
            # ç”¨æˆ·äº¤äº’ç»Ÿè®¡
            user_stats = interaction_matrix.groupby('user_id').agg({
                'song_id': ['nunique', 'count'],
                'total_weight': ['sum', 'mean', 'std']
            }).reset_index()
            
            # æ‰å¹³åŒ–åˆ—å
            user_stats.columns = ['user_id', 'unique_songs', 'total_interactions', 
                                 'total_weight_sum', 'avg_weight', 'weight_std']
            
            user_features = pd.merge(user_features, user_stats, on='user_id', how='left')
            
            # å¡«å……ç¼ºå¤±å€¼
            for col in ['unique_songs', 'total_interactions', 'total_weight_sum', 'avg_weight']:
                if col in user_features.columns:
                    user_features[col].fillna(0, inplace=True)
        
        # å¤„ç†ç¼ºå¤±å€¼
        print("2. å¤„ç†ç¼ºå¤±å€¼...")
        
        # å¹´é¾„
        if 'age' in user_features.columns:
            age_median = user_features['age'].median()
            user_features['age'].fillna(age_median, inplace=True)
        
        # æ€§åˆ«
        if 'gender' in user_features.columns:
            user_features['gender'].fillna(0, inplace=True)
        
        # ç‰¹å¾å·¥ç¨‹
        print("3. ç‰¹å¾å·¥ç¨‹...")
        
        # å¹´é¾„åˆ†ç»„
        if 'age' in user_features.columns:
            bins = [0, 18, 25, 35, 50, 100]
            labels = ['<18', '18-25', '26-35', '36-50', '>50']
            user_features['age_group'] = pd.cut(
                user_features['age'], bins=bins, labels=labels, right=False
            )
        
        # æ´»è·ƒåº¦åˆ†çº§
        if 'total_weight_sum' in user_features.columns:
            try:
                user_features['activity_level'] = pd.qcut(
                    user_features['total_weight_sum'], 
                    q=4, 
                    labels=['ä½æ´»è·ƒ', 'ä¸­ä½æ´»è·ƒ', 'ä¸­é«˜æ´»è·ƒ', 'é«˜æ´»è·ƒ'],
                    duplicates='drop'
                )
            except:
                user_features['activity_level'] = pd.cut(
                    user_features['total_weight_sum'],
                    bins=4,
                    labels=['ä½æ´»è·ƒ', 'ä¸­ä½æ´»è·ƒ', 'ä¸­é«˜æ´»è·ƒ', 'é«˜æ´»è·ƒ']
                )
        
        # äº¤äº’å¤šæ ·æ€§
        if 'unique_songs' in user_features.columns and 'total_interactions' in user_features.columns:
            user_features['diversity_ratio'] = user_features['unique_songs'] / user_features['total_interactions'].clip(lower=1)
        
        print(f"\nâœ“ ç”¨æˆ·ç‰¹å¾åˆ›å»ºå®Œæˆ! æœ€ç»ˆå½¢çŠ¶: {user_features.shape}")
        
        return user_features
    
    def filter_sparse_data(self, interaction_matrix, min_user_interactions=5, min_song_interactions=5):
        """è¿‡æ»¤ç¨€ç–æ•°æ®"""
        print("\n" + "="*80)
        print(f"è¿‡æ»¤ç¨€ç–æ•°æ® (ç”¨æˆ·â‰¥{min_user_interactions}æ¬¡, æ­Œæ›²â‰¥{min_song_interactions}æ¬¡)...")
        
        original_stats = {
            'users': interaction_matrix['user_id'].nunique(),
            'songs': interaction_matrix['song_id'].nunique(),
            'interactions': len(interaction_matrix)
        }
        
        # è¿‡æ»¤ä½é¢‘ç”¨æˆ·
        user_counts = interaction_matrix.groupby('user_id').size()
        active_users = user_counts[user_counts >= min_user_interactions].index
        
        # è¿‡æ»¤ä½é¢‘æ­Œæ›²
        song_counts = interaction_matrix.groupby('song_id').size()
        active_songs = song_counts[song_counts >= min_song_interactions].index
        
        filtered_matrix = interaction_matrix[
            interaction_matrix['user_id'].isin(active_users) & 
            interaction_matrix['song_id'].isin(active_songs)
        ].copy()
        
        filtered_stats = {
            'users': filtered_matrix['user_id'].nunique(),
            'songs': filtered_matrix['song_id'].nunique(),
            'interactions': len(filtered_matrix)
        }
        
        print(f"è¿‡æ»¤å‰: {original_stats['users']:,} ç”¨æˆ·, {original_stats['songs']:,} æ­Œæ›², {original_stats['interactions']:,} äº¤äº’")
        print(f"è¿‡æ»¤å: {filtered_stats['users']:,} ç”¨æˆ·, {filtered_stats['songs']:,} æ­Œæ›², {filtered_stats['interactions']:,} äº¤äº’")
        
        # è®¡ç®—ä¿ç•™æ¯”ä¾‹
        user_ratio = filtered_stats['users'] / original_stats['users'] if original_stats['users'] > 0 else 0
        song_ratio = filtered_stats['songs'] / original_stats['songs'] if original_stats['songs'] > 0 else 0
        interaction_ratio = filtered_stats['interactions'] / original_stats['interactions'] if original_stats['interactions'] > 0 else 0
        
        print(f"ä¿ç•™æ¯”ä¾‹: ç”¨æˆ· {user_ratio:.2%}, æ­Œæ›² {song_ratio:.2%}, äº¤äº’ {interaction_ratio:.2%}")
        
        return filtered_matrix
    
    def split_train_test(self, interaction_matrix, test_size=0.2, random_state=42):
        """åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
        print("\n" + "="*80)
        print("åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
        
        train_data = []
        test_data = []
        
        np.random.seed(random_state)
        
        for user_id in interaction_matrix['user_id'].unique():
            user_interactions = interaction_matrix[interaction_matrix['user_id'] == user_id]
            
            if len(user_interactions) >= 10:
                # æœ‰è¶³å¤Ÿæ•°æ®ï¼Œéšæœºåˆ’åˆ†
                n_test = max(1, int(len(user_interactions) * test_size))
                test_indices = np.random.choice(user_interactions.index, size=n_test, replace=False)
                train_indices = user_interactions.index.difference(test_indices)
                
                train_data.append(user_interactions.loc[train_indices])
                test_data.append(user_interactions.loc[test_indices])
            elif len(user_interactions) >= 3:
                # æ•°æ®è¾ƒå°‘ï¼Œç•™ä¸€æ¡ä½œä¸ºæµ‹è¯•
                test_indices = np.random.choice(user_interactions.index, size=1, replace=False)
                train_indices = user_interactions.index.difference(test_indices)
                
                train_data.append(user_interactions.loc[train_indices])
                test_data.append(user_interactions.loc[test_indices])
            else:
                # æ•°æ®å¤ªå°‘ï¼Œå…¨éƒ¨ä½œä¸ºè®­ç»ƒ
                train_data.append(user_interactions)
        
        if train_data:
            train_interactions = pd.concat(train_data, ignore_index=True)
        else:
            train_interactions = pd.DataFrame(columns=interaction_matrix.columns)
        
        if test_data:
            test_interactions = pd.concat(test_data, ignore_index=True)
        else:
            test_interactions = pd.DataFrame(columns=interaction_matrix.columns)
        
        print(f"è®­ç»ƒé›†: {len(train_interactions):,} æ¡è®°å½•")
        print(f"æµ‹è¯•é›†: {len(test_interactions):,} æ¡è®°å½•")
        print(f"åˆ’åˆ†æ¯”ä¾‹: {len(test_interactions)/(len(train_interactions)+len(test_interactions)):.2%}")
        
        return train_interactions, test_interactions
    
    def save_processed_data(self, song_features, user_features, 
                          interaction_matrix, train_interactions, test_interactions):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        print("\n" + "="*80)
        print("ä¿å­˜å¤„ç†åçš„æ•°æ®...")
        
        output_dir = "processed_data_complete"
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ­Œæ›²ç‰¹å¾
        song_features.to_csv(
            os.path.join(output_dir, "song_features_complete.csv"), index=False, encoding='utf-8'
        )
        print(f"âœ“ æ­Œæ›²ç‰¹å¾å·²ä¿å­˜ ({len(song_features):,} æ¡è®°å½•)")
        
        # ä¿å­˜ç”¨æˆ·ç‰¹å¾
        user_features.to_csv(
            os.path.join(output_dir, "user_features_complete.csv"), index=False, encoding='utf-8'
        )
        print(f"âœ“ ç”¨æˆ·ç‰¹å¾å·²ä¿å­˜ ({len(user_features):,} æ¡è®°å½•)")
        
        # ä¿å­˜äº¤äº’çŸ©é˜µ
        interaction_matrix.to_csv(
            os.path.join(output_dir, "interaction_matrix_complete.csv"), index=False, encoding='utf-8'
        )
        print(f"âœ“ äº¤äº’çŸ©é˜µå·²ä¿å­˜ ({len(interaction_matrix):,} æ¡è®°å½•)")
        
        # ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_interactions.to_csv(
            os.path.join(output_dir, "train_interactions_complete.csv"), index=False, encoding='utf-8'
        )
        test_interactions.to_csv(
            os.path.join(output_dir, "test_interactions_complete.csv"), index=False, encoding='utf-8'
        )
        print(f"âœ“ è®­ç»ƒé›†å·²ä¿å­˜ ({len(train_interactions):,} æ¡è®°å½•)")
        print(f"âœ“ æµ‹è¯•é›†å·²ä¿å­˜ ({len(test_interactions):,} æ¡è®°å½•)")
        
        # ä¿å­˜æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'n_songs': len(song_features),
            'n_users': len(user_features),
            'n_interactions': len(interaction_matrix),
            'n_train': len(train_interactions),
            'n_test': len(test_interactions),
            'train_test_ratio': len(test_interactions) / (len(train_interactions) + len(test_interactions)) 
                                if (len(train_interactions) + len(test_interactions)) > 0 else 0
        }
        
        with open(os.path.join(output_dir, "data_stats_complete.json"), 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"âœ“ æ•°æ®ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜")
        
        print("\næ‰€æœ‰æ•°æ®å·²ä¿å­˜å®Œæˆ!")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
        
        return stats

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹"""
    print("="*80)
    print("ç»Ÿä¸€éŸ³ä¹æ•°æ®é¢„å¤„ç†ç³»ç»Ÿ")
    print("="*80)
    
    try:
        # 1. åˆå§‹åŒ–å¤„ç†å™¨
        processor = UnifiedMusicDataProcessor(data_path=".")
        
        # 2. åŠ è½½æ‰€æœ‰æ•°æ®
        print("\né˜¶æ®µ1: åŠ è½½åŸå§‹æ•°æ®")
        processor.load_all_data_systematic()
        
        # 3. åˆ›å»ºç»Ÿä¸€çš„IDæ˜ å°„
        print("\né˜¶æ®µ2: åˆ›å»ºç»Ÿä¸€çš„IDæ˜ å°„")
        processor.create_unified_song_mapping()
        processor.create_unified_user_mapping()
        
        # 4. æ„å»ºäº¤äº’çŸ©é˜µ
        print("\né˜¶æ®µ3: æ„å»ºäº¤äº’çŸ©é˜µ")
        interaction_matrix = processor.build_interaction_matrix_with_mapping()
        
        # 5. è¿‡æ»¤ç¨€ç–æ•°æ®
        print("\né˜¶æ®µ4: è¿‡æ»¤ç¨€ç–æ•°æ®")
        filtered_matrix = processor.filter_sparse_data(
            interaction_matrix, 
            min_user_interactions=5, 
            min_song_interactions=5
        )
        
        # 6. åˆ›å»ºæ­Œæ›²ç‰¹å¾
        print("\né˜¶æ®µ5: åˆ›å»ºæ­Œæ›²ç‰¹å¾")
        song_features = processor.create_comprehensive_song_features()
        
        # 7. åˆ›å»ºç”¨æˆ·ç‰¹å¾
        print("\né˜¶æ®µ6: åˆ›å»ºç”¨æˆ·ç‰¹å¾")
        user_features = processor.create_comprehensive_user_features(filtered_matrix)
        
        # 8. è¿‡æ»¤ç‰¹å¾æ•°æ®ï¼Œåªä¿ç•™äº¤äº’çŸ©é˜µä¸­çš„ç”¨æˆ·å’Œæ­Œæ›²
        print("\né˜¶æ®µ7: å¯¹é½ç‰¹å¾æ•°æ®")
        
        # è¿‡æ»¤æ­Œæ›²ç‰¹å¾ï¼Œåªä¿ç•™åœ¨äº¤äº’çŸ©é˜µä¸­çš„æ­Œæ›²
        songs_in_interaction = set(filtered_matrix['song_id'].unique())
        song_features = song_features[song_features['song_id'].isin(songs_in_interaction)].copy()
        
        # è¿‡æ»¤ç”¨æˆ·ç‰¹å¾ï¼Œåªä¿ç•™åœ¨äº¤äº’çŸ©é˜µä¸­çš„ç”¨æˆ·
        users_in_interaction = set(filtered_matrix['user_id'].unique())
        user_features = user_features[user_features['user_id'].isin(users_in_interaction)].copy()
        
        # è¿‡æ»¤äº¤äº’çŸ©é˜µï¼Œåªä¿ç•™åœ¨ç‰¹å¾æ•°æ®ä¸­çš„ç”¨æˆ·å’Œæ­Œæ›²
        filtered_matrix = filtered_matrix[
            filtered_matrix['user_id'].isin(user_features['user_id']) & 
            filtered_matrix['song_id'].isin(song_features['song_id'])
        ].copy()
        
        print(f"å¯¹é½å: {song_features.shape[0]:,} æ­Œæ›², {user_features.shape[0]:,} ç”¨æˆ·, {len(filtered_matrix):,} äº¤äº’")
        
        # 9. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        print("\né˜¶æ®µ8: åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
        train_interactions, test_interactions = processor.split_train_test(filtered_matrix)
        
        # 10. ä¿å­˜å¤„ç†åçš„æ•°æ®
        print("\né˜¶æ®µ9: ä¿å­˜æ•°æ®")
        stats = processor.save_processed_data(
            song_features, user_features, filtered_matrix, 
            train_interactions, test_interactions
        )
        
        # 11. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*80)
        print("æ•°æ®å¤„ç†å®Œæˆ!")
        print("="*80)
        
        print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯:")
        print(f"1. æ­Œæ›²æ•°: {stats['n_songs']:,}")
        print(f"2. ç”¨æˆ·æ•°: {stats['n_users']:,}")
        print(f"3. æ€»äº¤äº’æ•°: {stats['n_interactions']:,}")
        print(f"4. è®­ç»ƒé›†å¤§å°: {stats['n_train']:,}")
        print(f"5. æµ‹è¯•é›†å¤§å°: {stats['n_test']:,}")
        print(f"6. æµ‹è¯•é›†æ¯”ä¾‹: {stats['train_test_ratio']:.2%}")
        
        # è®¡ç®—æ•°æ®å¯†åº¦
        if stats['n_users'] > 0 and stats['n_songs'] > 0:
            density = stats['n_interactions'] / (stats['n_users'] * stats['n_songs'])
            print(f"7. æ•°æ®å¯†åº¦: {density:.6f}")
        
        print("\nâœ… æ•°æ®å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆ!")
        print("æ‚¨å¯ä»¥ä½¿ç”¨å¤„ç†åçš„æ•°æ®è¿è¡Œæ¨èç³»ç»Ÿäº†ã€‚")
        
        return processor
        
    except Exception as e:
        print(f"\nâŒ ä¸»ç¨‹åºæ‰§è¡Œæ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
    processor = main()