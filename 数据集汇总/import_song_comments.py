# file: import_song_comments.py
"""
å°†åŸå§‹æ­Œæ›²è¯„è®ºæ•°æ®å¯¼å…¥åˆ° song_comments è¡¨
- è¯»å– song_comments_20260124_001212.csv
- é€šè¿‡ song_id_mapping è¡¨æˆ– enhanced_song_features è¡¨è·å– unified_song_id
- æ‰¹é‡æ’å…¥æ•°æ®åº“
"""

import pandas as pd
import numpy as np
import os
from sqlalchemy import create_engine, text
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def import_song_comments():
    print("="*80)
    print("å¯¼å…¥åŸå§‹è¯„è®ºæ•°æ®åˆ° song_comments è¡¨")
    print("="*80)
    
    # ---------- 1. æ•°æ®åº“é…ç½® ----------
    db_config = {
        'server': 'localhost',
        'database': 'MusicRecommendationDB',
        'username': 'sa',
        'password': '123456',   # â† è¯·ä¿®æ”¹ä¸ºæ‚¨çš„å¯†ç 
        'driver': 'ODBC Driver 18 for SQL Server'
    }
    conn_str = (f"mssql+pyodbc://{db_config['username']}:{db_config['password']}"
                f"@{db_config['server']}/{db_config['database']}"
                f"?driver={db_config['driver'].replace(' ', '+')}&Encrypt=no")
    engine = create_engine(conn_str, echo=False)
    
    # ---------- 2. è¯»å–åŸå§‹è¯„è®ºæ–‡ä»¶ ----------
    csv_file = "song_comments_20260124_001212.csv"
    if not os.path.exists(csv_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return
    
    print(f"ğŸ“„ è¯»å–è¯„è®ºæ–‡ä»¶: {csv_file}")
    df = pd.read_csv(csv_file)
    print(f"   åŸå§‹è®°å½•æ•°: {len(df)}")
    
    # ---------- 3. è·å–æ­Œæ›²IDæ˜ å°„ ----------
    with engine.connect() as conn:
        # æ–¹æ³•1ï¼šä» song_id_mapping è¡¨è·å–ï¼ˆä¼˜å…ˆï¼‰
        mapping_query = """
            SELECT original_song_id, unified_song_id 
            FROM song_id_mapping 
            WHERE original_song_id IS NOT NULL
        """
        mapping_df = pd.read_sql(mapping_query, conn)

        if len(mapping_df) == 0:
            # æ–¹æ³•2ï¼šç›´æ¥ä» enhanced_song_features è¡¨è·å–ï¼ˆæ³¨æ„åˆ—åå·²æ”¹ä¸º original_song_idï¼‰
            song_query = "SELECT song_id, original_song_id FROM enhanced_song_features WHERE original_song_id IS NOT NULL"
            song_df = pd.read_sql(song_query, conn)
            mapping_dict = dict(zip(song_df['original_song_id'].astype(str), song_df['song_id']))
        else:
            mapping_dict = dict(zip(mapping_df['original_song_id'].astype(str), mapping_df['unified_song_id']))
    
    print(f"âœ… è·å–æ­Œæ›²æ˜ å°„: {len(mapping_dict)} æ¡")
    
    # ---------- 4. æ•°æ®é¢„å¤„ç† ----------
    df = df.dropna(subset=['song_id', 'content'])
    df['song_id'] = df['song_id'].astype(str)
    df['unified_song_id'] = df['song_id'].map(mapping_dict)
    
    # è¿‡æ»¤æ— æ•ˆæ˜ å°„
    original_count = len(df)
    df = df[df['unified_song_id'].notna()]
    print(f"âœ… æœ‰æ•ˆæ˜ å°„: {len(df)} æ¡ (è¿‡æ»¤ {original_count - len(df)} æ¡)")
    
    if len(df) == 0:
        print("âŒ æ— æœ‰æ•ˆæ˜ å°„æ•°æ®ï¼Œè¯·æ£€æŸ¥æ­Œæ›²æ˜ å°„è¡¨")
        return
    
    # ---------- 5. å‡†å¤‡æ’å…¥æ•°æ® ----------
    # é‡å‘½ååˆ—ä»¥åŒ¹é…æ•°æ®åº“è¡¨
    df = df.rename(columns={
        'comment_id': 'original_comment_id',
        'user_id': 'original_user_id',
        'nickname': 'user_nickname',  # CSVä¸­å¯èƒ½æ²¡æœ‰ï¼Œéœ€è¦ç¡®è®¤
        'content': 'content',
        'liked_count': 'liked_count',
        'time': 'comment_time'
    })
    
    # å¤„ç†æ—¶é—´å­—æ®µ
    if 'comment_time' in df.columns:
        df['comment_time'] = pd.to_datetime(df['comment_time'], errors='coerce')
    
    # æ·»åŠ ç»Ÿä¸€æ­Œæ›²IDåˆ—
    df['unified_song_id'] = df['unified_song_id']
    
    # é€‰æ‹©éœ€è¦æ’å…¥çš„åˆ—
    insert_cols = [
        'unified_song_id', 'original_comment_id', 'original_user_id',
        'user_nickname', 'content', 'liked_count', 'comment_time'
    ]
    insert_cols = [col for col in insert_cols if col in df.columns]
    
    insert_df = df[insert_cols].copy()
    
    # ---------- 6. åˆ†æ‰¹å¯¼å…¥ ----------
    batch_size = 1000
    total = len(insert_df)
    success = 0
    
    print(f"\nâ³ å¼€å§‹å¯¼å…¥è¯„è®ºæ•°æ®ï¼Œå…± {total} æ¡...")
    
    for i in range(0, total, batch_size):
        batch = insert_df.iloc[i:i+batch_size]
        try:
            batch.to_sql('song_comments', engine, if_exists='append', index=False)
            success += len(batch)
            print(f"   è¿›åº¦: {success}/{total} ({success/total*100:.1f}%)")
        except Exception as e:
            print(f"   âŒ æ‰¹æ¬¡å¯¼å…¥å¤±è´¥ï¼Œå°è¯•é€æ¡æ’å…¥...")
            # é€æ¡æ’å…¥ï¼Œè·³è¿‡å¤±è´¥çš„å•æ¡
            for _, row in batch.iterrows():
                try:
                    row.to_frame().T.to_sql('song_comments', engine, if_exists='append', index=False)
                    success += 1
                except Exception as e2:
                    print(f"     è·³è¿‡è¯„è®º: {e2}")
            print(f"   è¿›åº¦: {success}/{total} ({success/total*100:.1f}%)")
    
    print(f"\nâœ… è¯„è®ºæ•°æ®å¯¼å…¥å®Œæˆ! æˆåŠŸ: {success} æ¡")
    
    # ---------- 7. ç»Ÿè®¡éªŒè¯ ----------
    with engine.connect() as conn:
        count = pd.read_sql("SELECT COUNT(*) as cnt FROM song_comments", conn)
        print(f"\nğŸ“Š song_comments è¡¨ç°åœ¨æœ‰ {count.iloc[0]['cnt']} æ¡è¯„è®º")
        
        song_count = pd.read_sql("""
            SELECT COUNT(DISTINCT unified_song_id) as cnt 
            FROM song_comments
        """, conn)
        print(f"   è¦†ç›–æ­Œæ›²æ•°: {song_count.iloc[0]['cnt']}")


if __name__ == "__main__":
    import_song_comments()