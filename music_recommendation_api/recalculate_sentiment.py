# recalculate_sentiment.py
import time
import logging
from sqlalchemy import create_engine, text
from datetime import datetime

from utils.sentiment_analyzer import analyze_music_sentiment

def analyze_sentiment_local(text):
    """ä½¿ç”¨æ–°çš„éŸ³ä¹æƒ…æ„Ÿåˆ†æå™¨"""
    score, _ = analyze_music_sentiment(str(text))
    return score

def analyze_sentiment_snownlp(text):
    """åŒæ—¶ä½¿ç”¨SnowNLPå’ŒéŸ³ä¹åˆ†æå™¨ï¼Œå–å¹³å‡"""
    try:
        from snownlp import SnowNLP
        s = SnowNLP(str(text))
        snow_score = s.sentiments
        
        # ä½¿ç”¨éŸ³ä¹åˆ†æå™¨
        music_score, _ = analyze_music_sentiment(str(text))
        
        # åŠ æƒå¹³å‡ï¼ŒéŸ³ä¹åˆ†æå™¨æƒé‡æ›´é«˜
        final_score = snow_score * 0.3 + music_score * 0.7
        
        return round(final_score, 3)
    except Exception as e:
        logger.warning(f"SnowNLPæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        # å›é€€åˆ°éŸ³ä¹åˆ†æå™¨
        score, _ = analyze_music_sentiment(str(text))
        return score

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_database_engine():
    """è·å–æ•°æ®åº“è¿æ¥"""
    connection_string = (
        "mssql+pyodbc://@localhost/MusicRecommendationDB?"
        "driver=ODBC+Driver+18+for+SQL+Server&"
        "Trusted_Connection=yes&"
        "Encrypt=no"
    )
    
    try:
        engine = create_engine(connection_string)
        # æµ‹è¯•è¿æ¥
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
        logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
        return engine
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        # å°è¯•å¤‡é€‰è¿æ¥æ–¹å¼
        alternatives = [
            "mssql+pyodbc://sa:123456/MusicRecommendationDB?driver=ODBC+Driver+18+for+SQL+Server&Encrypt=no",
        ]
        
        for conn_str in alternatives:
            try:
                engine = create_engine(conn_str)
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                logger.info(f"ä½¿ç”¨å¤‡é€‰è¿æ¥æ–¹å¼æˆåŠŸ")
                return engine
            except Exception:
                continue
        
        raise ConnectionError("æ‰€æœ‰è¿æ¥æ–¹å¼éƒ½å¤±è´¥äº†")

def analyze_sentiment_local(text):
    """æœ¬åœ°ç®€å•æƒ…æ„Ÿåˆ†æ"""
    text = str(text).lower()
    
    positive_words = ['å–œæ¬¢', 'å¥½å¬', 'çˆ±', 'æ£’', 'ä¼˜ç§€', 'ç»å…¸', 'å®Œç¾', 'èµ', 'æ”¯æŒ', 'æ¨è',
                     'èˆ’æœ', 'æ¸©æš–', 'æ„ŸåŠ¨', 'ç¾å¥½', 'å¥½å¬', 'åŠ¨å¬', 'ç¾å¦™', 'ä¼˜ç¾', 'æ„Ÿäºº',
                     'ç²¾å½©', 'å‡ºè‰²', 'æƒŠè‰³', 'è¶…èµ', 'æ— æ•Œ', 'å¤ªæ£’äº†', 'çˆ±äº†', 'ç¥æ›²', 'æ”¶è—',
                     'å¾ªç¯', 'å•æ›²å¾ªç¯', 'å¿…å¬', 'èˆ’é€‚', 'æƒ¬æ„', 'æ„‰æ‚¦', 'å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´',
                     'æ»¡æ„', 'æƒŠå–œ', 'äº«å—', 'é™¶é†‰', 'æ²‰é†‰', 'è¿·äºº', 'åŠ¨äºº', 'æ„Ÿäºº', 'æ²»æ„ˆ',
                     'æ”¾æ¾', 'èˆ’ç¼“', 'è½»æŸ”', 'æ¸©æŸ”', 'ç”œç¾', 'æ¸…æ–°', 'é˜³å…‰', 'æ­£èƒ½é‡']
    
    negative_words = ['è®¨åŒ', 'éš¾å¬', 'åƒåœ¾', 'å·®', 'ä¸å¥½', 'å¤±æœ›', 'çƒ‚', 'ä¸å–œæ¬¢', 'æ¶å¿ƒ',
                     'åˆºè€³', 'æ— èŠ', 'ç³Ÿç³•', 'åæ„Ÿ', 'å—ä¸äº†', 'åŠé€€', 'å¤±æœ›', 'æ— è¯­',
                     'æ‹‰èƒ¯', 'ä¸è¡Œ', 'å¼ƒäº†', 'å¿«è¿›', 'è·³è¿‡', 'ç—›è‹¦', 'éš¾å—', 'çƒ¦èº',
                     'åŒæ¶', 'é—æ†¾', 'åæ‚”', 'å·®åŠ²', 'ç³Ÿç³•', 'æ— è¯­', 'å¤±æœ›']
    
    positive_count = 0
    negative_count = 0
    
    for word in positive_words:
        if word in text:
            positive_count += 1
    
    for word in negative_words:
        if word in text:
            negative_count += 1
    
    total = positive_count + negative_count
    if total == 0:
        return 0.5  # ä¸­æ€§
    
    sentiment = 0.5 + (positive_count - negative_count) / (2 * total)
    return round(max(0.0, min(1.0, sentiment)), 3)

def analyze_sentiment_snownlp(text):
    """ä½¿ç”¨SnowNLPè¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
    try:
        from snownlp import SnowNLP
        s = SnowNLP(str(text))
        sentiment = s.sentiments
        return round(sentiment, 3)
    except Exception as e:
        logger.warning(f"SnowNLPæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        return None

def recalculate_sentiment(engine, use_snownlp=True, batch_size=500):
    """é‡æ–°è®¡ç®—æ‰€æœ‰è¯„è®ºçš„æƒ…æ„Ÿåˆ†æ•°"""
    start_time = time.time()
    
    # æ£€æŸ¥SnowNLPæ˜¯å¦å¯ç”¨
    if use_snownlp:
        try:
            from snownlp import SnowNLP
            logger.info("ä½¿ç”¨SnowNLPè¿›è¡Œæƒ…æ„Ÿåˆ†æ")
        except ImportError:
            logger.warning("SnowNLPæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æœ¬åœ°è¯åº“åˆ†æ")
            use_snownlp = False
    
    # è·å–æ‰€æœ‰è¯„è®º
    query = text("""
        SELECT comment_id, content 
        FROM song_comments 
        WHERE content IS NOT NULL AND LEN(content) > 0
        ORDER BY comment_id
    """)
    
    with engine.connect() as conn:
        result = conn.execute(query)
        comments = [(row.comment_id, row.content) for row in result]
    
    total = len(comments)
    logger.info(f"å¼€å§‹é‡æ–°è®¡ç®— {total} æ¡è¯„è®ºçš„æƒ…æ„Ÿåˆ†æ•°...")
    
    updated = 0
    errors = 0
    
    for i, (comment_id, content) in enumerate(comments):
        try:
            # ä½¿ç”¨æŒ‡å®šçš„æƒ…æ„Ÿåˆ†ææ–¹æ³•
            if use_snownlp:
                sentiment_score = analyze_sentiment_snownlp(content)
                if sentiment_score is None:  # å¦‚æœSnowNLPå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ–¹æ³•
                    sentiment_score = analyze_sentiment_local(content)
            else:
                sentiment_score = analyze_sentiment_local(content)
            
            # ç¡®å®šæƒ…æ„Ÿææ€§
            if sentiment_score > 0.6:
                is_positive = 1
            elif sentiment_score < 0.4:
                is_positive = 0
            else:
                is_positive = None
            
            # æ›´æ–°æ•°æ®åº“
            update_query = text("""
                UPDATE song_comments 
                SET sentiment_score = :sentiment, is_positive = :is_positive
                WHERE comment_id = :comment_id
            """)
            
            with engine.begin() as conn:
                conn.execute(update_query, {
                    "comment_id": comment_id,
                    "sentiment": sentiment_score,
                    "is_positive": is_positive
                })
            
            updated += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % batch_size == 0:
                elapsed = time.time() - start_time
                logger.info(f"è¿›åº¦: {i+1}/{total} ({((i+1)/total*100):.1f}%) - å·²æ›´æ–° {updated} æ¡ - è€—æ—¶: {elapsed:.1f}ç§’")
                
        except Exception as e:
            errors += 1
            logger.error(f"é‡æ–°è®¡ç®—è¯„è®º {comment_id} å¤±è´¥: {e}")
    
    # é‡æ–°è®¡ç®—æ­Œæ›²çš„å¹³å‡æƒ…æ„Ÿåˆ†æ•°
    logger.info("é‡æ–°è®¡ç®—æ­Œæ›²çš„å¹³å‡æƒ…æ„Ÿåˆ†æ•°...")
    recalc_song_sentiment_query = text("""
        UPDATE enhanced_song_features 
        SET avg_sentiment = s.avg_score
        FROM enhanced_song_features esf
        INNER JOIN (
            SELECT unified_song_id, AVG(CAST(sentiment_score as FLOAT)) as avg_score
            FROM song_comments 
            WHERE sentiment_score IS NOT NULL
            GROUP BY unified_song_id
        ) s ON esf.song_id = s.unified_song_id
    """)
    
    with engine.begin() as conn:
        result = conn.execute(recalc_song_sentiment_query)
        logger.info(f"æ›´æ–°äº† {result.rowcount} é¦–æ­Œæ›²çš„å¹³å‡æƒ…æ„Ÿåˆ†æ•°")
    
    # ç»Ÿè®¡ä¿¡æ¯
    elapsed = time.time() - start_time
    logger.info("="*60)
    logger.info("æƒ…æ„Ÿåˆ†æ•°é‡æ–°è®¡ç®—å®Œæˆ")
    logger.info(f"æ€»è¯„è®ºæ•°: {total}")
    logger.info(f"æˆåŠŸæ›´æ–°: {updated}")
    logger.info(f"å¤±è´¥: {errors}")
    logger.info(f"æ€»è€—æ—¶: {elapsed:.1f}ç§’")
    logger.info(f"å¹³å‡é€Ÿåº¦: {total/elapsed:.1f} æ¡/ç§’")
    logger.info(f"ä½¿ç”¨çš„æ–¹æ³•: {'SnowNLP' if use_snownlp else 'æœ¬åœ°è¯åº“'}")
    logger.info("="*60)
    
    return {
        "total_comments": total,
        "updated": updated,
        "errors": errors,
        "elapsed_time": elapsed,
        "method": "SnowNLP" if use_snownlp else "local"
    }

def get_statistics(engine):
    """è·å–æƒ…æ„Ÿåˆ†æç»Ÿè®¡ä¿¡æ¯"""
    logger.info("è·å–æƒ…æ„Ÿåˆ†æç»Ÿè®¡ä¿¡æ¯...")
    
    queries = {
        "æ€»è¯„è®ºæ•°": "SELECT COUNT(*) as count FROM song_comments",
        "æœ‰æƒ…æ„Ÿåˆ†æ•°çš„è¯„è®º": "SELECT COUNT(*) as count FROM song_comments WHERE sentiment_score IS NOT NULL",
        "æ­£é¢è¯„è®ºæ•°": "SELECT COUNT(*) as count FROM song_comments WHERE is_positive = 1",
        "è´Ÿé¢è¯„è®ºæ•°": "SELECT COUNT(*) as count FROM song_comments WHERE is_positive = 0",
        "ä¸­æ€§è¯„è®ºæ•°": "SELECT COUNT(*) as count FROM song_comments WHERE is_positive IS NULL",
        "å¹³å‡æƒ…æ„Ÿåˆ†æ•°": "SELECT AVG(CAST(sentiment_score as FLOAT)) as avg FROM song_comments WHERE sentiment_score IS NOT NULL",
        "æƒ…æ„Ÿåˆ†æ•°åˆ†å¸ƒ": """
            SELECT 
                CASE 
                    WHEN sentiment_score < 0.4 THEN 'è´Ÿé¢ (<0.4)'
                    WHEN sentiment_score >= 0.4 AND sentiment_score <= 0.6 THEN 'ä¸­æ€§ (0.4-0.6)'
                    WHEN sentiment_score > 0.6 THEN 'æ­£é¢ (>0.6)'
                    ELSE 'æœªçŸ¥'
                END as sentiment_range,
                COUNT(*) as count,
                COUNT(*) * 100.0 / (SELECT COUNT(*) FROM song_comments WHERE sentiment_score IS NOT NULL) as percentage
            FROM song_comments 
            WHERE sentiment_score IS NOT NULL
            GROUP BY 
                CASE 
                    WHEN sentiment_score < 0.4 THEN 'è´Ÿé¢ (<0.4)'
                    WHEN sentiment_score >= 0.4 AND sentiment_score <= 0.6 THEN 'ä¸­æ€§ (0.4-0.6)'
                    WHEN sentiment_score > 0.6 THEN 'æ­£é¢ (>0.6)'
                    ELSE 'æœªçŸ¥'
                END
            ORDER BY sentiment_range
        """
    }
    
    results = {}
    with engine.connect() as conn:
        for name, query in queries.items():
            try:
                result = conn.execute(text(query)).fetchone()
                if result:
                    results[name] = dict(result._mapping)
            except Exception as e:
                logger.error(f"æŸ¥è¯¢ {name} å¤±è´¥: {e}")
                results[name] = {"error": str(e)}
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("è¯„è®ºæƒ…æ„Ÿåˆ†æ•°é‡æ–°è®¡ç®—å·¥å…·")
    print("="*80)
    
    try:
        # è·å–æ•°æ®åº“è¿æ¥
        engine = get_database_engine()
        
        # æ˜¾ç¤ºå½“å‰ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å½“å‰ç»Ÿè®¡ä¿¡æ¯:")
        stats_before = get_statistics(engine)
        for name, data in stats_before.items():
            if isinstance(data, dict) and 'error' not in data:
                if 'avg' in data:
                    print(f"  {name}: {data['avg']:.3f}")
                elif 'count' in data:
                    print(f"  {name}: {data['count']:,}")
                elif 'percentage' in data:
                    print(f"  {name}: {data['sentiment_range']} - {data['count']:,} ({data['percentage']:.1f}%)")
        
        # è¯¢é—®æ˜¯å¦ä½¿ç”¨SnowNLP
        use_snownlp = input("\næ˜¯å¦ä½¿ç”¨SnowNLPè¿›è¡Œæƒ…æ„Ÿåˆ†æ? (y/n, é»˜è®¤y): ").strip().lower() in ['y', 'yes', '']
        
        if use_snownlp:
            try:
                from snownlp import SnowNLP
                print("âœ… SnowNLP å¯ç”¨")
            except ImportError:
                print("âŒ SnowNLP æœªå®‰è£…ï¼Œå°†ä½¿ç”¨æœ¬åœ°è¯åº“åˆ†æ")
                use_snownlp = False
        
        # ç¡®è®¤å¼€å§‹
        confirm = input(f"\nç¡®å®šè¦é‡æ–°è®¡ç®—æ‰€æœ‰è¯„è®ºçš„æƒ…æ„Ÿåˆ†æ•°å—? (y/n): ").strip().lower()
        if confirm not in ['y', 'yes']:
            print("æ“ä½œå·²å–æ¶ˆ")
            return
        
        # å¼€å§‹é‡æ–°è®¡ç®—
        print(f"\nå¼€å§‹é‡æ–°è®¡ç®—æƒ…æ„Ÿåˆ†æ•°...")
        print(f"ä½¿ç”¨çš„æ–¹æ³•: {'SnowNLP' if use_snownlp else 'æœ¬åœ°è¯åº“'}")
        
        result = recalculate_sentiment(engine, use_snownlp=use_snownlp)
        
        # æ˜¾ç¤ºé‡æ–°è®¡ç®—åçš„ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š é‡æ–°è®¡ç®—åçš„ç»Ÿè®¡ä¿¡æ¯:")
        stats_after = get_statistics(engine)
        for name, data in stats_after.items():
            if isinstance(data, dict) and 'error' not in data:
                if 'avg' in data:
                    print(f"  {name}: {data['avg']:.3f}")
                elif 'count' in data:
                    print(f"  {name}: {data['count']:,}")
                elif 'percentage' in data:
                    print(f"  {name}: {data['sentiment_range']} - {data['count']:,} ({data['percentage']:.1f}%)")
        
        print(f"\nâœ… æƒ…æ„Ÿåˆ†æ•°é‡æ–°è®¡ç®—å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()